{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Reshape, TimeDistributed\n",
    "from keras.layers.core import Dense, Activation, Dropout, Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import UpSampling1D, Conv1D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import TensorBoard\n",
    "from music21 import *\n",
    "import glob\n",
    "import numpy as np\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.callbacks import History, ModelCheckpoint\n",
    "from keras.optimizers import RMSprop\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '/home/eurismar/notebooks/Music_Generator_Demo/Pop_Music_Midi/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = glob.glob('{}/*.mid*'.format(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KEY_SIG_OFFSET = 0 \n",
    "melody_corpus = []\n",
    "for i, file in enumerate(files[:2]):\n",
    "#for file in files:\n",
    "    midi_stream = converter.parse(file)\n",
    "    \n",
    "    part0 = midi_stream[0]\n",
    "    key_sig = part0.keySignature\n",
    "    midi_stream.transpose(KEY_SIG_OFFSET - key_sig.tonic.pitchClass, inPlace=True)\n",
    "    for m in part0.measures(1, None):\n",
    "        if hasattr(m, 'flat'):\n",
    "            for nr in m.flat.notesAndRests:\n",
    "                pitch = nr.pitch.midi  if isinstance(nr, note.Note) else 0\n",
    "                duration = float(nr.quarterLength)\n",
    "                note_repr = (pitch, duration)\n",
    "                melody_corpus.append(note_repr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "melody_set = set(melody_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "notes_indices = {note: i for i, note in enumerate(melody_set)}\n",
    "indices_notes = {i: note for i, note in enumerate(melody_set)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "corpus_size = len(melody_set)\n",
    "print(corpus_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phrase_len = 20\n",
    "step_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phrases = []\n",
    "next_notes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 43\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(melody_corpus) - phrase_len, step_size):\n",
    "    phrases.append(melody_corpus[i: i + phrase_len])\n",
    "    next_notes.append(melody_corpus[i + phrase_len])\n",
    "print('nb sequences:', len(phrases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43, 20, 25)\n",
      "(43, 25)\n"
     ]
    }
   ],
   "source": [
    "# transform data into binary matrices\n",
    "X = np.zeros((len(phrases), phrase_len, corpus_size), dtype=np.bool)\n",
    "y = np.zeros((len(phrases), corpus_size), dtype=np.bool)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, phrase in enumerate(phrases):\n",
    "    for j, note in enumerate(phrase):\n",
    "        X[i, j, notes_indices[note]] = 1\n",
    "    y[i, notes_indices[next_notes[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_size=128\n",
    "batch_size = 128\n",
    "nb_epoch = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 20, 25)            0         \n",
      "_________________________________________________________________\n",
      "lstm_19 (LSTM)               (None, 20, 128)           78848     \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 20, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_20 (LSTM)               (None, 20, 128)           131584    \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 20, 128)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 20, 25)            3225      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 20, 25)            0         \n",
      "=================================================================\n",
      "Total params: 213,657\n",
      "Trainable params: 213,657\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_gen(G_in, phrase_len=phrase_len, corpus_size=corpus_size):\n",
    "    #G_in = Input(shape=(phrase_len, corpus_size))\n",
    "    layer = LSTM(layer_size, return_sequences=True)(G_in)\n",
    "    layer = Dropout(0.2)(layer)\n",
    "    layer = LSTM(layer_size, return_sequences=True)(layer)\n",
    "    layer = Dropout(0.2)(layer)\n",
    "    layer = TimeDistributed(Dense(corpus_size))(layer)\n",
    "    G_out = Activation('softmax')(layer)\n",
    "    LSTM_out = Activation('softmax')(layer)\n",
    "    G = Model(G_in, G_out)\n",
    "    G.compile(loss='categorical_crossentropy', optimizer=RMSprop(), metrics=['accuracy'])\n",
    "    return G, G_out\n",
    "G_in = Input(shape=(phrase_len, corpus_size))\n",
    "G, G_out = get_gen(G_in)\n",
    "G.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dis(D_in, phrase_len=phrase_len, corpus_size=corpus_size):\n",
    "    \n",
    "    #G_in = Input(shape=(phrase_len, corpus_size))\n",
    "    layer = LSTM(layer_size, return_sequences=True)(D_in)\n",
    "    layer = Dropout(0.2)(layer)\n",
    "    layer = LSTM(layer_size)(layer)\n",
    "    layer = Dropout(0.2)(layer)\n",
    "    layer = Dense(2)(layer)\n",
    "    D_out = Activation('sigmoid')(layer)\n",
    "    D = Model(D_in, D_out)\n",
    "    D.compile(loss='binary_crossentropy', optimizer=RMSprop(), metrics=['accuracy'])\n",
    "    return D, D_out    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_in = Input(shape=(phrase_len, corpus_size))\n",
    "#G_in = Input(shape=(phrase_len, corpus_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 20, 25)            0         \n",
      "_________________________________________________________________\n",
      "lstm_21 (LSTM)               (None, 20, 128)           78848     \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 20, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_22 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 2)                 258       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 210,690\n",
      "Trainable params: 210,690\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "D, D_out = get_dis(D_in)\n",
    "D.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_trainability(model, trainable=False):\n",
    "    model.trainable = trainable\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_gan(GAN_in, G, D):\n",
    "    set_trainability(D, False)\n",
    "    x = G(GAN_in) # ENTRADA DA GAN\n",
    "    GAN_out = D(x)\n",
    "    GAN = Model(GAN_in, GAN_out)\n",
    "    GAN.compile(loss='binary_crossentropy', optimizer=G.optimizer)\n",
    "    return GAN, GAN_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         (None, 20, 25)            0         \n",
      "_________________________________________________________________\n",
      "model_6 (Model)              (None, 20, 25)            213657    \n",
      "_________________________________________________________________\n",
      "model_7 (Model)              (None, 2)                 210690    \n",
      "=================================================================\n",
      "Total params: 424,347\n",
      "Trainable params: 213,657\n",
      "Non-trainable params: 210,690\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "GAN_in = Input(shape=(phrase_len, corpus_size))\n",
    "GAN, GAN_out = make_gan(GAN_in, G, D)\n",
    "GAN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_samples = 10\n",
    "noise_dim = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43, 20, 25)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43, 25)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_data_and_gen(G,n_samples=n_samples,noise_dim=noise_dim):\n",
    "    XT = X[:n_samples]\n",
    "    XN_noise = np.random.uniform(0, 1, size=[n_samples,phrase_len,noise_dim])\n",
    "    XN = G.predict(XN_noise)\n",
    "    print(XT.shape,XN.shape)\n",
    "    XX = np.concatenate((XT, XN))\n",
    "    yy = np.zeros((2*n_samples, 2))\n",
    "    yy[:n_samples, 1] = 1\n",
    "    yy[n_samples:, 0] = 1\n",
    "    return XX, yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pretrain(G, D, noise_dim=10, n_samples=10000, batch_size=32):\n",
    "    X, y = sample_data_and_gen(G, n_samples=n_samples, noise_dim=noise_dim)\n",
    "    set_trainability(D, True)\n",
    "    D.fit(X, y, epochs=1, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 20, 25) (10, 20, 25)\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 0s - loss: 0.0024 - acc: 1.0000     \n"
     ]
    }
   ],
   "source": [
    "pretrain(G, D,noise_dim = noise_dim, n_samples=n_samples,batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_noise(G, noise_dim=10, n_samples=10000):\n",
    "    X = np.random.uniform(0, 1, size=[n_samples,phrase_len, noise_dim])\n",
    "    y = np.zeros((n_samples, 2))\n",
    "    y[:, 1] = 1\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_loss = []\n",
    "g_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 25) (10, 20, 25)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-191-3a5cb404f916>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0md_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_data_and_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoise_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mset_trainability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0md_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-176-aca59518e152>\u001b[0m in \u001b[0;36msample_data_and_gen\u001b[0;34m(G, n_samples, noise_dim)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mXN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXN_noise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mXX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0myy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0myy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions"
     ]
    }
   ],
   "source": [
    "d_loss = []\n",
    "for epoch in range(2):\n",
    "    X, y = sample_data_and_gen(G, n_samples=10, noise_dim=noise_dim)\n",
    "    set_trainability(D, True)\n",
    "    d_loss.append(D.train_on_batch(X, y))\n",
    "    X, y = sample_noise(G, n_samples=n_samples, noise_dim=noise_dim)\n",
    "    set_trainability(D, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(GAN, G, D, epochs=500, n_samples=10000, noise_dim=10, batch_size=32, verbose=False, v_freq=50):\n",
    "    d_loss = []\n",
    "    g_loss = []\n",
    "    e_range = range(epochs)\n",
    "    if verbose:\n",
    "        e_range = tqdm(e_range)\n",
    "    for epoch in e_range:\n",
    "        #XT = X[:n_samples]\n",
    "        X, y = sample_data_and_gen(G, n_samples=10, noise_dim=noise_dim)\n",
    "        set_trainability(D, True)\n",
    "        d_loss.append(D.train_on_batch(X, y)) #TREINAMENTO ***************************************************\n",
    "        \n",
    "        X, y = sample_noise(G, n_samples=n_samples, noise_dim=noise_dim)\n",
    "        set_trainability(D, False)\n",
    "        g_loss.append(GAN.train_on_batch(X, y))\n",
    "        if verbose and (epoch + 1) % v_freq == 0:\n",
    "            print(\"Epoch #{}: Generative Loss: {}, Discriminative Loss: {}\".format(epoch + 1, g_loss[-1], d_loss[-1]))\n",
    "    return d_loss, g_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e28e74f37934a9da0768f996f435f46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking : expected input_1 to have shape (None, 20, 25) but got array with shape (10, 20, 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-25d2e2b96e22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0md_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGAN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-106-9d513bf16e7b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(GAN, G, D, epochs, n_samples, noise_dim, batch_size, verbose, v_freq)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0me_range\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m#XT = X[:n_samples]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_data_and_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoise_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mset_trainability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0md_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#TREINAMENTO ***************************************************\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-98-656600b8be6a>\u001b[0m in \u001b[0;36msample_data_and_gen\u001b[0;34m(G, n_samples, noise_dim)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mXT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mXN_noise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mphrase_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnoise_dim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mXN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXN_noise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXN_noise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1693\u001b[0m         x = _standardize_input_data(x, self._feed_input_names,\n\u001b[1;32m   1694\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m                                     check_batch_axis=False)\n\u001b[0m\u001b[1;32m   1696\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    142\u001b[0m                             \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                             \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m                             str(array.shape))\n\u001b[0m\u001b[1;32m    145\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking : expected input_1 to have shape (None, 20, 25) but got array with shape (10, 20, 10)"
     ]
    }
   ],
   "source": [
    "d_loss, g_loss = train(GAN, G, D, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ax = pd.DataFrame(\n",
    "    {\n",
    "        'Generative Loss': g_loss,\n",
    "        'Discriminative Loss': d_loss,\n",
    "    }\n",
    ").plot(title='Training loss', logy=True)\n",
    "ax.set_xlabel(\"Epochs\")\n",
    "ax.set_ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_VIEWED_SAMPLES = 2\n",
    "data_and_gen, _ = sample_data_and_gen(G, n_samples=N_VIEWED_SAMPLES)\n",
    "pd.DataFrame(np.transpose(data_and_gen[N_VIEWED_SAMPLES:])).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
